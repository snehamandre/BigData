{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c100000;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \cb3 \CocoaLigature0 rm -fr /Library/Python/Versions/2.5 - 2.6 - 2.7\
   99  conda install anaconda-clean\
  100  rm -fr Python/Versions/2.5 - 2.6 - 2.7\
  101  which python\
  102  sudo rm -fr Python/Versions/2.5 - 2.6 - 2.7\
  103  ls\
  104  sudo rm -fr Python/2.5 - 2.6 - 2.7\
  105  sudo rm -fr Python/2.6 - 2.7\
  106  sudo rm -fr Python/2.7\
  107  conda install\
  108  cd ..\
  109  jupyter notebook\
  110  pip install unittest\
  111  python -m unittest\
  112  jupyter notebook\
  113  exit\
  114  192.168.1.1\
  115  ping 192.168.1.1\
  116  export SPARK_HOME /Java/spark-2.4.0-bin-hadoop2.7 \
  117  pip install pyspark\
  118  export PYSPARK_DRIVER_PYTHON jupyter\
  119  export SPARK_HOME /Java/spark-2.4.0-bin-hadoop2.7 \
  120  export PYSPARK_DRIVER_PYTHON_OPTS 'notebook'\
  121  pyspark\
  122  pyspark\
  123  export SPARK_HOME /Java/spark-2.4.0-bin-hadoop2.7/\
  124  export SPARK_HOME /Java/spark-2.4.0-bin-hadoop2.7\
  125  export SPARK_HOME /Java/spark-2.4.0-bin-hadoop2.7/\
  126  export SPARK_HOME=/Java/spark-2.4.0-bin-hadoop2.7/\
  127  echo SPARK_HOME\
  128  echo $SPARK_HOME\
  129  export PYSPARK_DRIVER_PYTHON jupyter\
  130  echo $PYSPARK_DRIVER_PYTHON\
  131  env\
  132  export PYSPARK_DRIVER_PYTHON=jupyter\
  133  export PYSPARK_DRIVER_PYTHON_OPTS='notebook'\
  134  echo $PATH\
  135  export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin}